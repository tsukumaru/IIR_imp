
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Okapi BM25: a non-binary model</TITLE>
<META NAME="description" CONTENT="Okapi BM25: a non-binary model">
<META NAME="keywords" CONTENT="irbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="irbook.css">

<LINK REL="next" HREF="bayesian-network-approaches-to-ir-1.html">
<LINK REL="previous" HREF="tree-structured-dependencies-between-terms-1.html">
<LINK REL="up" HREF="an-appraisal-and-some-extensions-1.html">
<LINK REL="next" HREF="bayesian-network-approaches-to-ir-1.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html3186"
  HREF="bayesian-network-approaches-to-ir-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html3180"
  HREF="an-appraisal-and-some-extensions-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html3174"
  HREF="tree-structured-dependencies-between-terms-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html3182"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html3184"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html3187"
  HREF="bayesian-network-approaches-to-ir-1.html">Bayesian network approaches to</A>
<B> Up:</B> <A NAME="tex2html3181"
  HREF="an-appraisal-and-some-extensions-1.html">An appraisal and some</A>
<B> Previous:</B> <A NAME="tex2html3175"
  HREF="tree-structured-dependencies-between-terms-1.html">Tree-structured dependencies between terms</A>
 &nbsp; <B>  <A NAME="tex2html3183"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html3185"
  HREF="index-1.html">Index</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION001643000000000000000"></A><A NAME="sec:okapi-bm25"></A> <A NAME="p:okapi-bm25"></A>
<BR>
Okapi BM25: a non-binary model
</H2> 

<P>
The BIM was originally designed for short catalog records and abstracts of fairly consistent length, and it works reasonably in these contexts, but for modern full-text search collections, it seems clear that a model should pay attention to term frequency and document length, as in Chapter <A HREF="scoring-term-weighting-and-the-vector-space-model-1.html#ch:tfidf">6</A> . The <A NAME="14366"></A> <I>BM25 weighting scheme</I> , often called <A NAME="14368"></A> <I>Okapi weighting</I> , after the system in which it was first implemented, was developed as a way of building a probabilistic model sensitive to these quantities while not introducing too many additional parameters into the model (<A
 HREF="bibliography-1.html#sparckjones00probabilistic">Sp&#228;rck&nbsp;Jones et&nbsp;al., 2000</A>). We will not develop the full theory behind the model here, but just present a series of forms that build up to the standard form now used for document scoring. The simplest score for document <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img354.png"
 ALT="$d$"> is just idf weighting of the query terms present, as in Equation&nbsp;<A HREF="probability-estimates-in-practice-1.html#prob-idf">76</A>:
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
RSV_d = \sum_{t \in q} \log\frac{N}{\docf_t}
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><A NAME="bm25-1"></A><IMG
 WIDTH="129" HEIGHT="50" BORDER="0"
 SRC="img768.png"
 ALT="\begin{displaymath}
RSV_d = \sum_{t \in q} \log\frac{N}{\docf_t}
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(84)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
Sometimes, an alternative version of <A NAME="14378"></A> <I>idf</I>  is used.  If we start with the formula in Equation&nbsp;<A HREF="probability-estimates-in-theory-1.html#smoothed-rf">75</A> but in the absence of relevance feedback information we estimate that <IMG
 WIDTH="72" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img769.png"
 ALT="$S = s = 0$">, then we get an alternative idf formulation as follows:<A NAME="14513"></A>
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
RSV_d = \sum_{t \in q} \log \frac{N - \docf_t + \frac{1}{2}}{\docf_t + \frac{1}{2}}
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="191" HEIGHT="54" BORDER="0"
 SRC="img770.png"
 ALT="\begin{displaymath}
RSV_d = \sum_{t \in q} \log \frac{N - \docf_t + \frac{1}{2}}{\docf_t + \frac{1}{2}}
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(85)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
This variant behaves slightly strangely: if a term occurs in over half the documents in the collection then this model gives a negative term weight, which is presumably undesirable.  But, assuming the use of a stop list, this normally doesn't happen, and the value for each summand can be given a floor of 0.

<P>
We can improve on Equation&nbsp;<A HREF="#bm25-1">84</A> by factoring in the frequency of each term and document length:
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
RSV_d = \sum_{t \in q} \log\left[\frac{N}{\docf_t}\right]\cdot
\frac{(k_1 + 1)\termf_{td}}
{k_1 ((1-b) + b\times (L_d/ L_{ave})) + \termf_{td}}
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><A NAME="bm25-2"></A><IMG
 WIDTH="394" HEIGHT="51" BORDER="0"
 SRC="img771.png"
 ALT="\begin{displaymath}
RSV_d = \sum_{t \in q} \log\left[\frac{N}{\docf_t}\right]\cd...
...mf_{td}}
{k_1 ((1-b) + b\times (L_d/ L_{ave})) + \termf_{td}}
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(86)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
Here, <IMG
 WIDTH="26" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img772.png"
 ALT="$\termf_{td}$"> is the frequency of term <IMG
 WIDTH="10" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img67.png"
 ALT="$t$"> in document <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img354.png"
 ALT="$d$">, and <IMG
 WIDTH="21" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img773.png"
 ALT="$L_d$"><A NAME="Ld-notation"></A> and <IMG
 WIDTH="32" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img185.png"
 ALT="$ L_{ave}$"> are the length of document <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img354.png"
 ALT="$d$"> and the average document length for the whole collection.
The variable <IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img774.png"
 ALT="$k_1$"> is a positive tuning parameter that calibrates the document term frequency scaling. A <IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img774.png"
 ALT="$k_1$"> value of 0 corresponds to a binary model (no term frequency), and a large value corresponds to using raw term frequency. <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img137.png"
 ALT="$b$"> is another tuning parameter (<IMG
 WIDTH="72" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img775.png"
 ALT="$0 \le b \le 1$">) which determines the scaling by document length: <IMG
 WIDTH="41" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img776.png"
 ALT="$b = 1$"> corresponds to fully scaling the term weight by the document length, while <IMG
 WIDTH="42" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img777.png"
 ALT="$b = 0$"> corresponds to no length normalization.

<P>
If the query is long, then we might also use similar weighting for query terms. This is appropriate if the queries are paragraph long information needs, but unnecessary for short queries.
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
RSV_d = \sum_{t\in q} \left[\log\frac{N}{\docf_t}\right]
\cdot
\frac{(k_1+1)\termf_{td}}{k_1((1-b) + b \times (L_d/ L_{ave}))+\termf_{td}}
\cdot
\frac{(k_3 + 1)\termf_{tq}}{k_3 + \termf_{tq}}
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><A NAME="bm25-3"></A><IMG
 WIDTH="487" HEIGHT="52" BORDER="0"
 SRC="img778.png"
 ALT="\begin{displaymath}
RSV_d = \sum_{t\in q} \left[\log\frac{N}{\docf_t}\right]
\cd...
...mf_{td}}
\cdot
\frac{(k_3 + 1)\termf_{tq}}{k_3 + \termf_{tq}}
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(87)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
with <IMG
 WIDTH="26" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img779.png"
 ALT="$\termf_{tq}$"> being the frequency of term <IMG
 WIDTH="10" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img67.png"
 ALT="$t$"> in the query <IMG
 WIDTH="12" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img161.png"
 ALT="$q$">, and <IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img780.png"
 ALT="$k_3$"> being another positive tuning parameter that this time calibrates term frequency scaling of the query.  In the equation presented, there is no length normalization of queries (it is as if <IMG
 WIDTH="42" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img777.png"
 ALT="$b = 0$"> here).  Length normalization of the query is unnecessary because retrieval is being done with respect to a single fixed query.  The tuning parameters of these formulas should ideally be set to optimize performance on a development test collection (see page <A HREF="information-retrieval-system-evaluation-1.html#p:dev-test">8.1</A> ). That is, we can search for values of these parameters that maximize performance on a separate development test collection (either manually or with optimization methods such as grid search or something more advanced), and then use these parameters on the actual test collection. In the absence of such optimization, experiments have shown reasonable values are to set <IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img774.png"
 ALT="$k_1$"> and <IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img780.png"
 ALT="$k_3$"> to a value between 1.2 and 2 and <IMG
 WIDTH="62" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img781.png"
 ALT="$b = 0.75$">.

<P>
If we have relevance judgments available, then we can use the full form of smoothed-rf in place of the approximation <!-- MATH
 $\log(N/\docf_t)$
 -->
<IMG
 WIDTH="83" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img782.png"
 ALT="$\log(N/\docf_t)$"> introduced in prob-idf:
<BR>
<DIV ALIGN="CENTER"><A NAME="bm25"></A>
<!-- MATH
 \begin{eqnarray}
RSV_d &=& \sum_{t\in q} \log \left[\left[\frac{(|VR_t| + \frac{1}{2})/(|VNR_t| + \frac{1}{2})}
{(\docf_t - |VR_t| + \frac{1}{2})/(N - \docf_t - |VR| + |VR_t| + \frac{1}{2})}
 \right]\right.\\
& & \left.\kern1.5em \times
\frac{(k_1+1)\termf_{td}}{k_1((1-b) + b (L_d/ L_{ave}))+\termf_{td}}
\times
\frac{(k_3 + 1)\termf_{tq}}{k_3 + \termf_{tq}}\right]
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT"><IMG
 WIDTH="42" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img783.png"
 ALT="$\displaystyle RSV_d$"></TD>
<TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img313.png"
 ALT="$\textstyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP><IMG
 WIDTH="424" HEIGHT="64" ALIGN="MIDDLE" BORDER="0"
 SRC="img784.png"
 ALT="$\displaystyle \sum_{t\in q} \log \left[\left[\frac{(\vert VR_t\vert + \frac{1}{...
.../(N - \docf_t - \vert VR\vert + \vert VR_t\vert + \frac{1}{2})}
\right]\right.$"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(88)</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT">&nbsp;</TD>
<TD>&nbsp;</TD>
<TD ALIGN="LEFT" NOWRAP><IMG
 WIDTH="370" HEIGHT="57" ALIGN="MIDDLE" BORDER="0"
 SRC="img785.png"
 ALT="$\displaystyle \left.\kern1.5em \times
\frac{(k_1+1)\termf_{td}}{k_1((1-b) + b (...
...ve}))+\termf_{td}}
\times
\frac{(k_3 + 1)\termf_{tq}}{k_3 + \termf_{tq}}\right]$"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(89)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
Here, <IMG
 WIDTH="32" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img748.png"
 ALT="$VR_t$">, <IMG
 WIDTH="46" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img786.png"
 ALT="$NVR_t$">, and <IMG
 WIDTH="27" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img600.png"
 ALT="$VR$"> are used as in Section <A HREF="probabilistic-approaches-to-relevance-feedback-1.html#sec:probrf">11.3.4</A> . The first part of the expression reflects relevance feedback (or just idf weighting if no relevance information is available), the second implements document term frequency and document length scaling, and the third considers term frequency in the query.

<P>
Rather than just providing a term weighting method for terms in a user's query, relevance feedback can also involve augmenting the query (automatically or with manual review) with some (say, 10-20) of the top terms in the known-relevant documents as ordered by the relevance factor <IMG
 WIDTH="16" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img787.png"
 ALT="$\hat{c}_t$"> from Equation&nbsp;<A HREF="probability-estimates-in-theory-1.html#smoothed-rf">75</A>, and the above formula can then be used with such an augmented query vector <IMG
 WIDTH="11" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img572.png"
 ALT="$\vec{q}$">.

<P>
The BM25 term weighting formulas have been used quite widely and quite successfully across a range of collections and search tasks.  Especially in the TREC evaluations, they performed well and were widely adopted by many groups.  See <A
 HREF="bibliography-1.html#sparckjones00probabilistic">Sp&#228;rck&nbsp;Jones et&nbsp;al. (2000)</A> for extensive motivation and discussion of experimental results.

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html3186"
  HREF="bayesian-network-approaches-to-ir-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html3180"
  HREF="an-appraisal-and-some-extensions-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html3174"
  HREF="tree-structured-dependencies-between-terms-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html3182"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html3184"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html3187"
  HREF="bayesian-network-approaches-to-ir-1.html">Bayesian network approaches to</A>
<B> Up:</B> <A NAME="tex2html3181"
  HREF="an-appraisal-and-some-extensions-1.html">An appraisal and some</A>
<B> Previous:</B> <A NAME="tex2html3175"
  HREF="tree-structured-dependencies-between-terms-1.html">Tree-structured dependencies between terms</A>
 &nbsp; <B>  <A NAME="tex2html3183"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html3185"
  HREF="index-1.html">Index</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
&copy; 2008 Cambridge University Press<br>This is an automatically generated page. In case of formatting errors you may want to look at the <a href=http://informationretrieval.org>PDF edition</a> of the book.<br>
2009-04-07
</ADDRESS>
</BODY>
</HTML>
