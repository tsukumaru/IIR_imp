
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Markov chains</TITLE>
<META NAME="description" CONTENT="Markov chains">
<META NAME="keywords" CONTENT="irbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="irbook.css">

<LINK REL="next" HREF="the-pagerank-computation-1.html">
<LINK REL="previous" HREF="pagerank-1.html">
<LINK REL="up" HREF="pagerank-1.html">
<LINK REL="next" HREF="definition-1.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html5025"
  HREF="definition-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html5019"
  HREF="pagerank-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html5013"
  HREF="pagerank-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html5021"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html5023"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html5026"
  HREF="definition-1.html">Definition:</A>
<B> Up:</B> <A NAME="tex2html5020"
  HREF="pagerank-1.html">PageRank</A>
<B> Previous:</B> <A NAME="tex2html5014"
  HREF="pagerank-1.html">PageRank</A>
 &nbsp; <B>  <A NAME="tex2html5022"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html5024"
  HREF="index-1.html">Index</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION002621000000000000000"></A>
<A NAME="sec:markov"></A> <A NAME="p:markov"></A>
<BR>
Markov chains
</H2> 
A Markov chain is a <EM>discrete-time stochastic process:</EM> a process that occurs in a series of time-steps in each of which a random choice is made. A Markov chain consists of <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img62.png"
 ALT="$N$"> <EM>states</EM>. Each web page will correspond to a state in the Markov chain we will formulate.

<P>
A Markov chain is characterized by an <IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1555.png"
 ALT="$N \times N$"> <EM>transition probability matrix</EM> <IMG
 WIDTH="14" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$P$"><A NAME="transition-notation"></A> each of whose entries is in the interval <IMG
 WIDTH="36" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img356.png"
 ALT="$[0,1]$">; the entries in each row of <IMG
 WIDTH="14" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$P$"> add up to 1. The Markov chain can be in one of the <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img62.png"
 ALT="$N$"> states at any given time-step; then, the entry <IMG
 WIDTH="21" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1895.png"
 ALT="$P_{ij}$"> tells us the probability that the state at the next time-step is <IMG
 WIDTH="9" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img9.png"
 ALT="$j$">, conditioned on the current state being <IMG
 WIDTH="8" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$i$">. Each entry <IMG
 WIDTH="21" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1895.png"
 ALT="$P_{ij}$"> is known as a transition probability and depends only on the current state <IMG
 WIDTH="8" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$i$">; this is known as the Markov property. Thus, by the Markov property, <BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
\forall i,j, P_{ij}\in[0,1]
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="102" HEIGHT="30" BORDER="0"
 SRC="img1896.png"
 ALT="\begin{displaymath}\forall i,j, P_{ij}\in[0,1]\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(251)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
and
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
\forall i, \sum_{j=1}^N P_{ij}=1.
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><A NAME="eqnstochastic"></A><IMG
 WIDTH="95" HEIGHT="56" BORDER="0"
 SRC="img1897.png"
 ALT="\begin{displaymath}
\forall i, \sum_{j=1}^N P_{ij}=1.\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(252)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
A matrix with non-negative entries that satisfies Equation&nbsp;<A HREF="#eqnstochastic">252</A> is known as a <A NAME="32267"></A> <I>stochastic matrix</I> . A key property of a stochastic matrix is that it has a <A NAME="32269"></A> <I>principal left eigenvector</I>  corresponding to its largest eigenvalue, which is 1.

<P>
In a Markov chain, the probability distribution of next states for a Markov chain depends only on the current state, and not on how the Markov chain arrived at the current state. Figure <A HREF="#fig:figmarkov">21.2</A>  shows a simple Markov chain with three states.  From the middle state A, we proceed with (equal) probabilities of 0.5 to either B or C.  From either B or C, we proceed with probability 1 to A.  The transition probability matrix of this Markov chain is then

<P>
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
\left(
  \begin{array}{ccc}
    0 & 0.5 & 0.5 \\
    1 & 0 & 0 \\
    1 & 0 & 0 \\
  \end{array}
\right)
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="114" HEIGHT="64" BORDER="0"
 SRC="img1898.png"
 ALT="\begin{displaymath}
\left(
\begin{array}{ccc}
0 &amp; 0.5 &amp; 0.5 \\
1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
\end{array}\right)
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(253)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>

<P>

<DIV ALIGN="CENTER"><A NAME="fig:figmarkov"></A><A NAME="p:figmarkov"></A><A NAME="32294"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 21.2:</STRONG>
A simple Markov chain with three states; the numbers on the links indicate the transition probabilities.</CAPTION>
<TR><TD><IMG
 WIDTH="200" HEIGHT="51" BORDER="0"
 SRC="img1899.png"
 ALT="\begin{figure}\begin{picture}(700,80)\thicklines
\put(150,40){\circle{25}}
\p...
...{0.5}
\put(190,35){\vector(-1,0){30}}
\put(175,25){1}
\end{picture}
\end{figure}"></TD></TR>
</TABLE>
</DIV>

<P>
A Markov chain's probability distribution over its states may be viewed as a <A NAME="32298"></A> <I>probability vector</I> : a vector all of whose entries are in the interval <IMG
 WIDTH="36" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img356.png"
 ALT="$[0,1]$">, and the entries add up to 1. An <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img62.png"
 ALT="$N$">-dimensional probability vector each of whose components corresponds to one of the <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img62.png"
 ALT="$N$"> states of a Markov chain can be viewed as a probability distribution over its states.  For our simple Markov chain of Figure <A HREF="#fig:figmarkov">21.2</A> , the probability vector would have 3 components that sum to 1.

<P>
We can view a random surfer on the web graph as a Markov chain, with one state for each web page, and each transition probability representing the probability of moving from one web page to another. The teleport operation contributes to these transition probabilities.  The adjacency matrix <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img167.png"
 ALT="$A$"><A NAME="adjacency-notation"></A> of the web graph is defined as follows: if there is a hyperlink from page <IMG
 WIDTH="8" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$i$"> to page <IMG
 WIDTH="9" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img9.png"
 ALT="$j$">, then <IMG
 WIDTH="55" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1900.png"
 ALT="$A_{ij}=1$">, otherwise <IMG
 WIDTH="55" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1901.png"
 ALT="$A_{ij}=0$">. We can readily derive the transition probability matrix <IMG
 WIDTH="14" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$P$"> for our Markov chain from the <IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1555.png"
 ALT="$N \times N$"> matrix <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img167.png"
 ALT="$A$">:

<OL>
<LI>If a row of <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img167.png"
 ALT="$A$"> has no 1's, then replace each element by 1/N.  For all other rows proceed as follows.
</LI>
<LI>Divide each 1 in <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img167.png"
 ALT="$A$"> by the number of 1's in its row.  Thus, if there is a row with three 1's, then each of them is replaced by <IMG
 WIDTH="30" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1902.png"
 ALT="$1/3$">.
</LI>
<LI>Multiply the resulting matrix by <IMG
 WIDTH="40" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1893.png"
 ALT="$1-\alpha$">.
</LI>
<LI>Add <IMG
 WIDTH="37" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1903.png"
 ALT="$\alpha/N$"> to every entry of the resulting matrix, to obtain <IMG
 WIDTH="14" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$P$">.
</LI>
</OL>

<P>
We can depict the probability distribution of the surfer's position at any time by a probability vector <IMG
 WIDTH="13" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img701.png"
 ALT="$\vec{x}$">. At <IMG
 WIDTH="39" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1904.png"
 ALT="$t=0$"> the surfer may begin at a state whose corresponding entry in <IMG
 WIDTH="13" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img701.png"
 ALT="$\vec{x}$"> is 1 while all others are zero. By definition, the surfer's distribution at <IMG
 WIDTH="40" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1905.png"
 ALT="$t=1$"> is given by the probability vector <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1906.png"
 ALT="$\vec{x}P$">; at <IMG
 WIDTH="40" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1907.png"
 ALT="$t=2$"> by <!-- MATH
 $(\vec{x}P)P=\vec{x}P^2$
 -->
<IMG
 WIDTH="95" HEIGHT="36" ALIGN="MIDDLE" BORDER="0"
 SRC="img1908.png"
 ALT="$(\vec{x}P)P=\vec{x}P^2$">, and so on. We will detail this process in Section <A HREF="the-pagerank-computation-1.html#sec:prank">21.2.2</A> . We can thus compute the surfer's distribution over the states at any time, given only the initial distribution and the transition probability matrix <IMG
 WIDTH="14" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$P$">.

<P>
If a Markov chain is allowed to run for many time steps, each state is visited at a (different) frequency that depends on the structure of the Markov chain. In our running analogy, the surfer visits certain web pages (say, popular news home pages) more often than other pages. We now make this intuition precise, establishing conditions under which such the visit frequency converges to fixed, steady-state quantity. Following this, we set the PageRank of each node <IMG
 WIDTH="12" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img615.png"
 ALT="$v$"> to this steady-state visit frequency and show how it can be computed.

<P>
<BR><HR>
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><UL>
<LI><A NAME="tex2html5027"
  HREF="definition-1.html">Definition:</A>
</UL></UL>
<!--End of Table of Child-Links-->
<HR>
<!--Navigation Panel-->
<A NAME="tex2html5025"
  HREF="definition-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html5019"
  HREF="pagerank-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html5013"
  HREF="pagerank-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html5021"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html5023"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html5026"
  HREF="definition-1.html">Definition:</A>
<B> Up:</B> <A NAME="tex2html5020"
  HREF="pagerank-1.html">PageRank</A>
<B> Previous:</B> <A NAME="tex2html5014"
  HREF="pagerank-1.html">PageRank</A>
 &nbsp; <B>  <A NAME="tex2html5022"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html5024"
  HREF="index-1.html">Index</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
&copy; 2008 Cambridge University Press<br>This is an automatically generated page. In case of formatting errors you may want to look at the <a href=http://informationretrieval.org>PDF edition</a> of the book.<br>
2009-04-07
</ADDRESS>
</BODY>
</HTML>
