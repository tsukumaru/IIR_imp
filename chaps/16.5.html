
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Model-based clustering</TITLE>
<META NAME="description" CONTENT="Model-based clustering">
<META NAME="keywords" CONTENT="irbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="irbook.css">

<LINK REL="next" HREF="references-and-further-reading-16.html">
<LINK REL="previous" HREF="k-means-1.html">
<LINK REL="up" HREF="flat-clustering-1.html">
<LINK REL="next" HREF="references-and-further-reading-16.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html4252"
  HREF="references-and-further-reading-16.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html4246"
  HREF="flat-clustering-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html4240"
  HREF="cluster-cardinality-in-k-means-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html4248"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html4250"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html4253"
  HREF="references-and-further-reading-16.html">References and further reading</A>
<B> Up:</B> <A NAME="tex2html4247"
  HREF="flat-clustering-1.html">Flat clustering</A>
<B> Previous:</B> <A NAME="tex2html4241"
  HREF="cluster-cardinality-in-k-means-1.html">Cluster cardinality in K-means</A>
 &nbsp; <B>  <A NAME="tex2html4249"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html4251"
  HREF="index-1.html">Index</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->

<H1><A NAME="SECTION002150000000000000000"></A>
<A NAME="sec:modelclustering"></A> <A NAME="p:modelclustering"></A>
<BR>
Model-based clustering
</H1> 

<P>
In this section, we describe a generalization of
 <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, the EM algorithm. It can be applied to a
larger variety of document representations and distributions
than  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means.

<P>
In  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, we attempt to find centroids that are good
representatives. We can view the set of <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$"> centroids as a model that
generates the data. Generating a document in this model consists of
first picking a centroid at random and then adding some noise. If the
noise is normally distributed, this procedure will result in
clusters of spherical shape. 
<A NAME="24900"></A> <I>Model-based clustering</I> 
assumes
that the data were generated by a model and tries to
recover the original model from the data. The model that we
recover from the data then
defines clusters and an assignment of documents to clusters.

<P>
A commonly used criterion for estimating the model parameters
is maximum
likelihood. In  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, 
the quantity <!-- MATH
 $\exp(-\mbox{RSS})$
 -->
<IMG
 WIDTH="83" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1482.png"
 ALT="$\exp(-\mbox{RSS})$"> is proportional to the
likelihood that a particular model (i.e., a set of centroids) generated
the data. For  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, 
maximum likelihood 
and minimal RSS are equivalent criteria.
We denote the model parameters by <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$\Theta$">.
In  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, 
<!-- MATH
 $\Theta = \{ \vec{\mu}_1, \ldots ,\vec{\mu}_K \}$
 -->
<IMG
 WIDTH="126" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1483.png"
 ALT="$\Theta = \{ \vec{\mu}_1, \ldots ,\vec{\mu}_K \}$">. 

<P>
More generally, the
maximum likelihood criterion is
to select the parameters <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$\Theta$"> that maximize the log-likelihood
of generating the data <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1484.png"
 ALT="$D$">:
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
\Theta  = \argmax_{\Theta}  L(D|\Theta)
= 
\argmax_{\Theta} \log \prod_{n=1}^N P(d_n | \Theta) 
=
\argmax_{\Theta} \sum_{n=1}^N \log P(d_n| \Theta)
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="525" HEIGHT="52" BORDER="0"
 SRC="img1485.png"
 ALT="\begin{displaymath}
\Theta = \argmax_{\Theta} L(D\vert\Theta)
=
\argmax_{\Theta...
...heta)
=
\argmax_{\Theta} \sum_{n=1}^N \log P(d_n\vert \Theta)
\end{displaymath}"></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(198)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
<IMG
 WIDTH="58" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1486.png"
 ALT="$L(D\vert\Theta)$"> is the objective function that measures
the goodness of the clustering. Given two
clusterings with the same number of clusters, we prefer the
one with higher <IMG
 WIDTH="58" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1486.png"
 ALT="$L(D\vert\Theta)$">.

<P>
This is the same approach we took in Chapter <A HREF="language-models-for-information-retrieval-1.html#ch:lmodels">12</A> 
(page <A HREF="finite-automata-and-language-models-1.html#p:generativemodel">12.1.1</A> ) for language modeling and in
Section <A HREF="the-text-classification-problem-1.html#sec:classificationproblem">13.1</A>  (page <A HREF="properties-of-naive-bayes-1.html#p:generativemodel2">13.4</A> ) for text
classification. In text classification, we chose the class
that maximizes the likelihood of generating a particular
document. Here, we choose the clustering <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$\Theta$"> that
maximizes the likelihood of generating a given set of
documents.  Once we have <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$\Theta$">, we
can compute an assignment probability
<!-- MATH
 $P(d|\omega_k;\Theta)$
 -->
<IMG
 WIDTH="80" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1487.png"
 ALT="$P(d\vert\omega_k;\Theta)$"> for each document-cluster pair. This
set of assignment probabilities defines a soft clustering.

<P>
An example of a soft assignment is
that
a document about
Chinese cars may have a fractional membership of 0.5 in each of the
two clusters China and automobiles, reflecting the fact
that both topics are pertinent. A hard clustering like
 <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means cannot
model this simultaneous relevance to two topics.

<P>
Model-based clustering provides a
framework for incorporating our knowledge about a domain.
 <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means and the
hierarchical algorithms in Chapter <A HREF="hierarchical-clustering-1.html#ch:hierclust">17</A> 
make fairly rigid assumptions about the data. For example,
clusters in  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means are assumed to be spheres.
Model-based clustering offers more flexibility. The
clustering model can be adapted to what we know about the
underlying distribution of the data, be it
Bernoulli (as in
the example in Table <A HREF="#tab:clusttb4">16.3</A> ), Gaussian with non-spherical variance
(another model that is important
in document clustering) or a member of a different family.

<P>
A commonly used algorithm for model-based clustering 
is the
<A NAME="24926"></A> <I>Expectation-Maximization algorithm</I>  or 
<A NAME="24928"></A> <I>EM algorithm</I> .
EM clustering is an iterative algorithm that maximizes
<IMG
 WIDTH="58" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1486.png"
 ALT="$L(D\vert\Theta)$">.
EM can be applied to many different types of probabilistic
modeling.  
We will work with a mixture
of multivariate Bernoulli distributions here, the distribution we know from
Section <A HREF="the-binary-independence-model-1.html#sec:bim">11.3</A>  
(page <A HREF="the-binary-independence-model-1.html#p:bim">11.3</A> )
and Section <A HREF="the-bernoulli-model-1.html#sec:twomodels">13.3</A>  (page <A HREF="the-bernoulli-model-1.html#p:twomodels">13.3</A> ):
<BR>
<DIV ALIGN="CENTER"><A NAME="emdocprob"></A>
<!-- MATH
 \begin{eqnarray}
P(d| \omega_k ; \Theta) = 
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT"><IMG
 WIDTH="303" HEIGHT="64" ALIGN="MIDDLE" BORDER="0"
 SRC="img1488.png"
 ALT="$\displaystyle P(d\vert \omega_k ; \Theta) =
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)$"></TD>
<TD>&nbsp;</TD>
<TD>&nbsp;</TD>
<TD WIDTH=10 ALIGN="RIGHT">
(199)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
where <!-- MATH
 $\Theta = \{ \Theta_1,\ldots,\Theta_K \}$
 -->
<IMG
 WIDTH="133" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1489.png"
 ALT="$\Theta = \{ \Theta_1,\ldots,\Theta_K \} $">,
<!-- MATH
 $\Theta_k = (\alpha_k , q_{1k}, \ldots, q_{Mk})$
 -->
<IMG
 WIDTH="162" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1490.png"
 ALT="$\Theta_k = (\alpha_k , q_{1k}, \ldots, q_{Mk})$">,
and  <!-- MATH
 $q_{mk} = P(\wvar_m=1 | \omega_k)$
 -->
<IMG
 WIDTH="151" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1491.png"
 ALT="$q_{mk} = P(\wvar_m=1 \vert \omega_k)$">
are the parameters of the
model.<A NAME="tex2html184"
  HREF="footnode.html#foot25265"><SUP><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/footnote.png"></SUP></A><!-- MATH
 $P(\wvar_m=1|\omega_k)$
 -->
<IMG
 WIDTH="104" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1494.png"
 ALT="$P(\wvar_m=1\vert\omega_k)$">
is the probability that
a document from cluster <IMG
 WIDTH="22" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1396.png"
 ALT="$\omega_k$"> contains term <IMG
 WIDTH="20" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1493.png"
 ALT="$\tcword_m$">.
The probability <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1495.png"
 ALT="$\alpha_k$"> is the
prior  of cluster <IMG
 WIDTH="22" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1396.png"
 ALT="$\omega_k$">: the probability that a
document <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img354.png"
 ALT="$d$"> is in <IMG
 WIDTH="22" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1396.png"
 ALT="$\omega_k$">
if we
have no information about <IMG
 WIDTH="12" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img354.png"
 ALT="$d$">. 

<P>
The mixture model then is:
<BR>
<DIV ALIGN="CENTER"><A NAME="emdocprob2"></A>
<!-- MATH
 \begin{eqnarray}
P(d| \Theta) = 
\sum_{k=1}^{K} \alpha_k 
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT"><IMG
 WIDTH="321" HEIGHT="64" ALIGN="MIDDLE" BORDER="0"
 SRC="img1496.png"
 ALT="$\displaystyle P(d\vert \Theta) =
\sum_{k=1}^{K} \alpha_k
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)$"></TD>
<TD>&nbsp;</TD>
<TD>&nbsp;</TD>
<TD WIDTH=10 ALIGN="RIGHT">
(200)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
In this model, we generate a document by
first picking a cluster <IMG
 WIDTH="11" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$k$"> with probability <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1495.png"
 ALT="$\alpha_k$"> and
then generating the terms of the document according to the
parameters <IMG
 WIDTH="28" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1497.png"
 ALT="$q_{mk}$">.
Recall that the document
representation of the multivariate Bernoulli is a vector of
<IMG
 WIDTH="20" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img186.png"
 ALT="$M$"> Boolean values (and not a real-valued vector).

<P>
How do we use EM to infer the parameters
of the clustering
from the data? That is, how do we choose parameters <IMG
 WIDTH="17" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$\Theta$"> that
maximize 
<IMG
 WIDTH="58" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1486.png"
 ALT="$L(D\vert\Theta)$">?
EM is similar to  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means
in that it alternates between an <A NAME="24957"></A> <I>expectation step</I> ,
corresponding to reassignment, and a <A NAME="24959"></A> <I>maximization step</I> ,
corresponding to recomputation of the parameters of the model. The
parameters of  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means are the centroids, the parameters of the
instance of EM in this section are the <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1495.png"
 ALT="$\alpha_k$"> and 
<IMG
 WIDTH="28" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1497.png"
 ALT="$q_{mk}$">.

<P>
The maximization step
recomputes the conditional parameters 
<IMG
 WIDTH="28" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1497.png"
 ALT="$q_{mk}$">
and the priors <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1495.png"
 ALT="$\alpha_k$">
as follows:

<P>
<BR>
<DIV ALIGN="CENTER"><A NAME="eqn:wgc"></A>
<!-- MATH
 \begin{eqnarray}
\mbox{\bf Maximization step:} \quad
q_{mk} = \frac{\sum_{n=1}^N r_{nk} I( \tcword_m \in d_n )}
{\sum_{n=1}^N  r_{nk}} \quad \alpha_k = \frac{\sum_{n=1}^N r_{nk}}{N}
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT"><IMG
 WIDTH="458" HEIGHT="61" ALIGN="MIDDLE" BORDER="0"
 SRC="img1498.png"
 ALT="$\displaystyle \mbox{\bf Maximization step:} \quad
q_{mk} = \frac{\sum_{n=1}^N r...
...\in d_n )}
{\sum_{n=1}^N r_{nk}} \quad \alpha_k = \frac{\sum_{n=1}^N r_{nk}}{N}$"></TD>
<TD>&nbsp;</TD>
<TD>&nbsp;</TD>
<TD WIDTH=10 ALIGN="RIGHT">
(201)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
where <!-- MATH
 $I( \tcword_m \in d_n )=1$
 -->
<IMG
 WIDTH="108" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1499.png"
 ALT="$I( \tcword_m \in d_n )=1$"> if <!-- MATH
 $\tcword_m \in d_n$
 -->
<IMG
 WIDTH="56" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1500.png"
 ALT="$\tcword_m \in d_n$"> and
0 otherwise and
<IMG
 WIDTH="24" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1501.png"
 ALT="$r_{nk}$"> is the soft
assignment of document <IMG
 WIDTH="20" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1502.png"
 ALT="$d_n$"> to cluster <IMG
 WIDTH="11" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$k$"> as computed in 
the preceding iteration. (We'll address the issue of
initialization in a moment.)
These are the maximum likelihood estimates for the
parameters of the multivariate Bernoulli  from
Table <A HREF="#tab:nbmodelcomparison">13.3</A>  (page <A HREF="#p:nbmodelcomparison">13.3</A> )
except that  documents are assigned fractionally
to clusters here. 
These maximum likelihood estimates
maximize the likelihood of the data given the model.

<P>
The expectation step computes the soft assignment of
documents to clusters given the current parameters <IMG
 WIDTH="28" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1497.png"
 ALT="$q_{mk}$">
and <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1495.png"
 ALT="$\alpha_k$">:

<P>
<BR>
<DIV ALIGN="CENTER"><A NAME="eqn:emexpectation"></A>
<!-- MATH
 \begin{eqnarray}
{\bf Expectation \ step:} \quad
r_{nk} = \frac{ \alpha_k (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}{\sum_{k=1}^{K} \alpha_k (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT"><IMG
 WIDTH="471" HEIGHT="57" ALIGN="MIDDLE" BORDER="0"
 SRC="img1503.png"
 ALT="$\displaystyle {\bf Expectation \ step:} \quad
r_{nk} = \frac{ \alpha_k (\prod_{...
... (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}$"></TD>
<TD>&nbsp;</TD>
<TD>&nbsp;</TD>
<TD WIDTH=10 ALIGN="RIGHT">
(202)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
This expectation step applies 
 and <A HREF="#emdocprob2">200</A>  to computing the likelihood that <IMG
 WIDTH="22" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1396.png"
 ALT="$\omega_k$"> generated document
<IMG
 WIDTH="20" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1502.png"
 ALT="$d_n$">. It is the classification procedure for
the multivariate Bernoulli in Table <A HREF="#tab:nbmodelcomparison">13.3</A> . Thus, the
expectation step is nothing else but Bernoulli Naive Bayes
classification (including normalization, i.e. dividing by
the denominator, to get a
probability distribution over clusters).

<P>
<BR><P></P>
<DIV ALIGN="CENTER">

<P>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">(a)</TD>
<TD ALIGN="LEFT">docID</TD>
<TD ALIGN="LEFT">document text</TD>
<TD ALIGN="LEFT">docID</TD>
<TD ALIGN="LEFT">document text</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">1</TD>
<TD ALIGN="LEFT">hot chocolate cocoa beans</TD>
<TD ALIGN="LEFT">7</TD>
<TD ALIGN="LEFT">sweet sugar</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">2</TD>
<TD ALIGN="LEFT">cocoa ghana africa</TD>
<TD ALIGN="LEFT">8</TD>
<TD ALIGN="LEFT">sugar cane brazil</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">3</TD>
<TD ALIGN="LEFT">beans harvest ghana</TD>
<TD ALIGN="LEFT">9</TD>
<TD ALIGN="LEFT">sweet sugar beet</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">4</TD>
<TD ALIGN="LEFT">cocoa butter</TD>
<TD ALIGN="LEFT">10</TD>
<TD ALIGN="LEFT">sweet cake icing</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">5</TD>
<TD ALIGN="LEFT">butter truffles</TD>
<TD ALIGN="LEFT">11</TD>
<TD ALIGN="LEFT">cake black forest</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">6</TD>
<TD ALIGN="LEFT">sweet chocolate</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
</TR>
</TABLE>

<P>
<BR>
<BR>

<P>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">(b)</TD>
<TD ALIGN="LEFT">Parameter</TD>
<TD ALIGN="CENTER" COLSPAN=8>Iteration of clustering</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0</TD>
<TD ALIGN="LEFT">1</TD>
<TD ALIGN="LEFT">2</TD>
<TD ALIGN="LEFT">3</TD>
<TD ALIGN="LEFT">4</TD>
<TD ALIGN="LEFT">5</TD>
<TD ALIGN="LEFT">15</TD>
<TD ALIGN="LEFT">25</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1504.png"
 ALT="$\alpha_1$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.45</TD>
<TD ALIGN="LEFT">0.53</TD>
<TD ALIGN="LEFT">0.57</TD>
<TD ALIGN="LEFT">0.58</TD>
<TD ALIGN="LEFT">0.54</TD>
<TD ALIGN="LEFT">0.45</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1505.png"
 ALT="$r_{1,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1506.png"
 ALT="$r_{2,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.79</TD>
<TD ALIGN="LEFT">0.99</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1507.png"
 ALT="$r_{3,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.84</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1508.png"
 ALT="$r_{4,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.75</TD>
<TD ALIGN="LEFT">0.94</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1509.png"
 ALT="$r_{5,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.52</TD>
<TD ALIGN="LEFT">0.66</TD>
<TD ALIGN="LEFT">0.91</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1510.png"
 ALT="$r_{6,1}$"></TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">1.00</TD>
<TD ALIGN="LEFT">0.83</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1511.png"
 ALT="$r_{7,1}$"></TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1512.png"
 ALT="$r_{8,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="26" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1513.png"
 ALT="$r_{9,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="32" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1514.png"
 ALT="$r_{10,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.40</TD>
<TD ALIGN="LEFT">0.14</TD>
<TD ALIGN="LEFT">0.01</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="32" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1515.png"
 ALT="$r_{11,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.50</TD>
<TD ALIGN="LEFT">0.57</TD>
<TD ALIGN="LEFT">0.58</TD>
<TD ALIGN="LEFT">0.41</TD>
<TD ALIGN="LEFT">0.07</TD>
<TD ALIGN="LEFT">0.00</TD>
<TD ALIGN="LEFT">0.00</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="54" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1516.png"
 ALT="$q_{africa,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.100</TD>
<TD ALIGN="LEFT">0.134</TD>
<TD ALIGN="LEFT">0.158</TD>
<TD ALIGN="LEFT">0.158</TD>
<TD ALIGN="LEFT">0.169</TD>
<TD ALIGN="LEFT">0.200</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="54" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1517.png"
 ALT="$q_{africa,2}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.083</TD>
<TD ALIGN="LEFT">0.042</TD>
<TD ALIGN="LEFT">0.001</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1518.png"
 ALT="$q_{brazil,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="52" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1519.png"
 ALT="$q_{brazil,2}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.167</TD>
<TD ALIGN="LEFT">0.195</TD>
<TD ALIGN="LEFT">0.213</TD>
<TD ALIGN="LEFT">0.214</TD>
<TD ALIGN="LEFT">0.196</TD>
<TD ALIGN="LEFT">0.167</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="49" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1520.png"
 ALT="$q_{cocoa,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.400</TD>
<TD ALIGN="LEFT">0.432</TD>
<TD ALIGN="LEFT">0.465</TD>
<TD ALIGN="LEFT">0.474</TD>
<TD ALIGN="LEFT">0.508</TD>
<TD ALIGN="LEFT">0.600</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="50" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1521.png"
 ALT="$q_{cocoa,2}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.167</TD>
<TD ALIGN="LEFT">0.090</TD>
<TD ALIGN="LEFT">0.014</TD>
<TD ALIGN="LEFT">0.001</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1522.png"
 ALT="$q_{sugar,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
<TD ALIGN="LEFT">0.000</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1523.png"
 ALT="$q_{sugar,2}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">1.000</TD>
<TD ALIGN="LEFT">0.500</TD>
<TD ALIGN="LEFT">0.585</TD>
<TD ALIGN="LEFT">0.640</TD>
<TD ALIGN="LEFT">0.642</TD>
<TD ALIGN="LEFT">0.589</TD>
<TD ALIGN="LEFT">0.500</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="50" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1524.png"
 ALT="$q_{sweet,1}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">1.000</TD>
<TD ALIGN="LEFT">0.300</TD>
<TD ALIGN="LEFT">0.238</TD>
<TD ALIGN="LEFT">0.180</TD>
<TD ALIGN="LEFT">0.159</TD>
<TD ALIGN="LEFT">0.153</TD>
<TD ALIGN="LEFT">0.000</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT"><IMG
 WIDTH="50" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1525.png"
 ALT="$q_{sweet,2}$"></TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">1.000</TD>
<TD ALIGN="LEFT">0.417</TD>
<TD ALIGN="LEFT">0.507</TD>
<TD ALIGN="LEFT">0.610</TD>
<TD ALIGN="LEFT">0.640</TD>
<TD ALIGN="LEFT">0.608</TD>
<TD ALIGN="LEFT">0.667</TD>
</TR>
</TABLE>

The EM clustering algorithm.The table shows a set of documents (a)
and parameter values for selected iterations during EM
clustering (b).
Parameters shown are prior
<IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1504.png"
 ALT="$\alpha_1$">, soft assignment scores
<IMG
 WIDTH="27" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1526.png"
 ALT="$r_{n,1}$"> (both omitted for cluster&nbsp;2), and lexical
parameters <IMG
 WIDTH="31" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1527.png"
 ALT="$q_{m,k}$"> for a few terms.
The authors initially assigned document&nbsp;6 to cluster&nbsp;1
and document&nbsp;7 to cluster&nbsp;2  (iteration 0). EM converges after 25 iterations.
For smoothing, the <IMG
 WIDTH="24" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1501.png"
 ALT="$r_{nk}$"> in
Equation&nbsp;<A HREF="#eqn:wgc">201</A> were replaced with <!-- MATH
 $r_{nk}+\epsilon$
 -->
<IMG
 WIDTH="51" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1528.png"
 ALT="$r_{nk}+\epsilon$"> where
<!-- MATH
 $\epsilon = 0.0001$
 -->
<IMG
 WIDTH="78" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1529.png"
 ALT="$\epsilon = 0.0001$">.

<A NAME="tab:clusttb4"></A> <A NAME="p:clusttb4"></A>  

</DIV>
<BR>

<P>
We clustered a set of 11 documents into two clusters using
EM in Table <A HREF="#tab:clusttb4">16.3</A> .
After convergence in iteration&nbsp;25, the first 5 documents are
assigned to cluster&nbsp;1 (<!-- MATH
 $r_{i,1} = 1.00$
 -->
<IMG
 WIDTH="74" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1530.png"
 ALT="$r_{i,1} = 1.00$">) and the last 6 to
cluster&nbsp;2 (<IMG
 WIDTH="74" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1531.png"
 ALT="$r_{i,1}=0.00$">). Somewhat atypically, the final assignment is a hard
assignment here.
EM usually converges to a soft assignment.
In iteration&nbsp;25, the prior <IMG
 WIDTH="19" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1504.png"
 ALT="$\alpha_1$"> for cluster&nbsp;1 is
<!-- MATH
 $5/11 \approx 0.45$
 -->
<IMG
 WIDTH="88" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img1532.png"
 ALT="$5/11 \approx 0.45$"> because 5 of the 11 documents
are in cluster&nbsp;1. Some terms are quickly associated with one
cluster because the initial assignment can ``spread'' to them
unambiguously. For example, 
membership in cluster&nbsp;2 spreads 
from document 7 to document 8 in the first iteration because they share
sugar (<IMG
 WIDTH="56" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1533.png"
 ALT="$r_{8,1}=0$"> in iteration 1).

<P>
For parameters of terms occurring in
ambiguous contexts, convergence takes longer. Seed
documents 6 and 7 both contain sweet. As a result, it
takes 25 iterations for the term to be unambiguously
associated with cluster 2. (<IMG
 WIDTH="80" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img1534.png"
 ALT="$q_{sweet,1}=0$"> in iteration 25.)

<P>
Finding good seeds is even more critical for EM than for
 <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means. EM is prone to get stuck in  local optima if the
seeds are not chosen well. This is a general problem
that also occurs in other applications of EM.<A NAME="tex2html185"
  HREF="footnode.html#foot25272"><SUP><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/footnote.png"></SUP></A>Therefore, as with  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means, the initial assignment of
documents to clusters is often computed by a different
algorithm. For example, a hard  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means clustering may
provide the initial assignment, which EM can then ``soften up.''

<P>
<B>Exercises.</B>
<UL>
<LI>We saw above that the time complexity of  <IMG
 WIDTH="15" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$K$">-means is
<IMG
 WIDTH="79" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img1460.png"
 ALT="$\Theta(IKNM)$">. What is the time complexity of EM?

<P>
</LI>
</UL><HR>
<!--Navigation Panel-->
<A NAME="tex2html4252"
  HREF="references-and-further-reading-16.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/next.png"></A> 
<A NAME="tex2html4246"
  HREF="flat-clustering-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/up.png"></A> 
<A NAME="tex2html4240"
  HREF="cluster-cardinality-in-k-means-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/prev.png"></A> 
<A NAME="tex2html4248"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/contents.png"></A> 
<A NAME="tex2html4250"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="http://nlp.stanford.edu/IR-book/html/icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html4253"
  HREF="references-and-further-reading-16.html">References and further reading</A>
<B> Up:</B> <A NAME="tex2html4247"
  HREF="flat-clustering-1.html">Flat clustering</A>
<B> Previous:</B> <A NAME="tex2html4241"
  HREF="cluster-cardinality-in-k-means-1.html">Cluster cardinality in K-means</A>
 &nbsp; <B>  <A NAME="tex2html4249"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html4251"
  HREF="index-1.html">Index</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
&copy; 2008 Cambridge University Press<br>This is an automatically generated page. In case of formatting errors you may want to look at the <a href=http://informationretrieval.org>PDF edition</a> of the book.<br>
2009-04-07
</ADDRESS>
</BODY>
</HTML>
